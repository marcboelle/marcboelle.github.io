---
layout: distill
title: fairness with Wasserstein barycenters
description: Fair Regression with Wasserstein Barycenters by Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Luca Oneto, and Massimiliano Pontil
tags: fairness math wasserstein polytechnique
categories: paper-study
giscus_comments: false
date: 2023-12-05
featured: false
thumbnail: assets/img/fairness/fairness.gif

bibliography: 2018-12-22-distill.bib

toc:
  - name: The challenge of algorithmic fairness
    # subsections:
    #   - name: The gossip problem
  - name: Results of the paper
  - name: Implementation

# Below is an example of injecting additional post-specific styles.
# If you use this post as a template, delete this _styles block.
# _styles: >
#   .fake-img {
#     background: #bbb;
#     border: 1px solid rgba(0, 0, 0, 0.1);
#     box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
#     margin-bottom: 12px;
#   }
#   .fake-img p {
#     font-family: monospace;
#     color: white;
#     text-align: left;
#     margin: 12px 0;
#     text-align: center;
#     font-size: 16px;
#   }

---

## The challenge of algorithmic fairness
When training a Machine Learning model, we make our predictor learn from the data which can be biased. For instance, if we want to decide how much an applicant would be paid, there will be a difference (in the reference data) between the wages of men and comen. But ideally,  So the question is : how can we build a fair predictor when the training data is biased?


## Results of the paper

### Problem setting

The authors focus on regression problems $$Y=f^*(X,S)+\xi$$, where $$f^*$$ is the regression function minimizing the squared risk, $$S$$ a sensitive attribute and $$\xi$$ a (centered) noise.

### Demographic Parity (DP)

To evaluate the fairness of some predictors, there are different metrics available. Demographic Parity is one of them and extensively used in the literature, in particular in this paper. Intuitively, it is satisfied if the distribution of the prediction is independent of the sensitive attribute.

Formally, with $$S$$ the attribute representing the sensitive groups in the population, a predictor $$g$$ is fair (according to the DP criterion) if 
$$\forall (s,s')\in S^2,\:\:\sup_{t\in\mathbb{R}}\left|\mathbb{P}(g(X,S)\leq t|S=s)-\mathbb{P}(g(X,S)\leq t|S=s')\right|=0$$
In other words, the Kolmogorov-Smirnov distance between the distributions on all sensitive groups must be $$0$$.

### Strategy of the authors

From the optimal predictor $$f^*$$, the authors suggests that we build a fair predictor $$g^*$$ (w.r.t. DP) which remains "close" to $$f^*$$ - to keep the accuracy as high as possible. We end up with this new problem :
$$\min_{g\text{ is fair}}\mathbb{E}\left(f^*(X,S)-g(X,S)\right)^2$$

Using Optimal Transport theory, the authors provide a closed form expression of $$g^*$$ using Wasserstein barycenters 

## Implementation