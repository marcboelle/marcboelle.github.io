<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://marcboelle.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://marcboelle.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-10-29T22:01:59+00:00</updated><id>https://marcboelle.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Modeling long-term energy storage in the United States</title><link href="https://marcboelle.github.io/blog/2024/LDES/" rel="alternate" type="text/html" title="Modeling long-term energy storage in the United States"/><published>2024-07-30T00:00:00+00:00</published><updated>2024-07-30T00:00:00+00:00</updated><id>https://marcboelle.github.io/blog/2024/LDES</id><content type="html" xml:base="https://marcboelle.github.io/blog/2024/LDES/"><![CDATA[<p>internship report available <a href="/assets/pdf/LDES_report.pdf">here</a></p> <p></p>]]></content><author><name></name></author><category term="internship"/><category term="berkeley"/><category term="research"/><category term="modeling"/><category term="energy"/><category term="storage"/><category term="optimization"/><summary type="html"><![CDATA[From my 4-months research internship at Lawrence Berkeley National Laboratory (LBNL), in the Grid Integration Group]]></summary></entry><entry><title type="html">statistical studies on four datasets - course final project</title><link href="https://marcboelle.github.io/blog/2023/MAP565/" rel="alternate" type="text/html" title="statistical studies on four datasets - course final project"/><published>2023-12-08T00:00:00+00:00</published><updated>2023-12-08T00:00:00+00:00</updated><id>https://marcboelle.github.io/blog/2023/MAP565</id><content type="html" xml:base="https://marcboelle.github.io/blog/2023/MAP565/"><![CDATA[]]></content><author><name></name></author><category term="implementation"/><category term="polytechnique"/><category term="math"/><category term="dataset"/><summary type="html"><![CDATA[GARCH and Hawkes processes, copulas, time series analysis. Project report from the course MAP565 at École Polytechnique (in French)]]></summary></entry><entry><title type="html">accelerated gossip</title><link href="https://marcboelle.github.io/blog/2023/gossip/" rel="alternate" type="text/html" title="accelerated gossip"/><published>2023-12-05T00:00:00+00:00</published><updated>2023-12-05T00:00:00+00:00</updated><id>https://marcboelle.github.io/blog/2023/gossip</id><content type="html" xml:base="https://marcboelle.github.io/blog/2023/gossip/"><![CDATA[<p>reference paper available <a href="https://arxiv.org/abs/1805.08531">here</a> <d-cite key="gossip"></d-cite></p> <p>Framework (gossip problem): Given a network of agents represented as a graph, in which each agent holds a real value, we want to estimate the average of these values in a distributed manner. The agents (nodes) are related through links (edges), which they can use to communicate.</p> <p>The authors build a method for solving this problem that depends only on what they define as the <em>spectral dimension of the network</em>, which is intuitively the dimension of the space in which the agents live (for the grid in \(\mathbb{Z}^n\), the spectral dimension is \(n\)). Their method shows improvement over previous algorithms in the non-asymptotic regime, when the values are far from fully mixed.</p> <h2 id="the-gossip-problem-and-gossip-algorithms">The gossip problem and gossip algorithms</h2> <h3 id="the-gossip-problem">The gossip problem</h3> <p>The gossip problem, also known as the averaging problem, is fundamental in distributed frameworks, when information is shared among several machines without a central server. In this framework, we assume that each machine can communicate only with a few others, and these links are represented in a graph \(G=(V,E)\). Each machine hold an initial real value that the others do not know. The goal is then to find a way to get each machine to know the average of these initial values, through an iterative communication procedure and as quickly as possible.</p> <h4 id="problem-setting">Problem Setting</h4> <p>We are given an undirected finite graph \(G=(V,E)\), where \(V\) is the set of agents (nodes) in the network, and \(E\) the set of communication links (edges). Each node \(v\in V\) receives an initial real value \(\xi_v\) called an observation. We denote by \(\xi=(\xi_v)_{v\in V}\) the vector of observations, and the goal is then for each machine to know \(\bar\xi=\frac{1}{|V|}\sum_{v\in V}\xi_v\) through an iterative algorithm.</p> <p>\(x^t=(x^t_v)_{v\in V}\) denotes the values at time \(t\).</p> <p>NB : we are in in a synchronous framework, meaning that at every time step, all communciations are made at the same time (and not successively)</p> <h3 id="first-gossip-algorithms">First gossip algorithms</h3> <h4 id="simple-gossip">Simple gossip</h4> <p>Referred to as <em>simple gossip</em> in the paper, the landmark algorithm consists in the following intuitive scheme: at each iteration, each agent replaces his current value by an average of the values held by its neighbors. Formally, this means that we have a <strong>gossip matrix</strong> \(W\), which is stochastic, symmetric, nonnegative and supported by the graph : \(W_{u,v}&gt;0\implies \{u,v\}\in E\).</p> <p>Usual gossip matrices :</p> <ul> <li>in a \(d\)-regular graph (all vertices have degree \(d\)): \(W\)</li> <li>more generally, if all vertices have degree smaller than \(d_{\max}\): \(W\)</li> </ul> <p>Then the simple gossip algorithm consists in the updates \(x^{t+1}=Wx^t\). So \(x^t=W^t\xi\)</p> <h4 id="shift-register-gossip">Shift-register gossip</h4> <p>The idea of this second gossip algorithm is to take a linear combination of past iterates : \(x^{t+1}=\omega Wx^t+(1-\omega)x^{t-1}\) with \(x^0=\xi\) and \(x^1=W\xi\) Without going into the details of this algorithm, it is clear that the parameter \(\omega\) plays an important role and must be finetuned. It was shown in other papers (CITE?) that \(\omega=2\frac{1-\sqrt{\gamma(1-\gamma/4)}}{(1-\gamma/2)^2}\), which depends on the spectral gap gamma, works well, with an acceleration of convergence for small gammas (compared to simple gossip).</p> <p>This is a nice improvement since \(\gamma\) is indeed very small in large graphs. And in practicle cases, graph networks are quite big so it is a worthy improvement.</p> <p>Yet one important point here is that <strong>we assume that all agents know the spectral gap</strong> \(\gamma\). But in the general case, there is no reason why they should. Thus, the point of this paper is to find a way to avoid this difficulty by building a method based not on \(\gamma\) but on the spectral dimension of the graph.</p> <p><img src="../assets/img/gossip/grid-graph-Z2.png" alt="graph of spectral dimension $$2$$ in $$\mathbb{Z}^2$$"/></p> <h2 id="acceleration-with-jacobi-polynomials">Acceleration with Jacobi Polynomials</h2> <h3 id="polynomial-gossip">Polynomial gossip</h3> <p>Intuitively, polynomial gossip consists in replacing \(x^t=W^t\xi\) by \(x^t=P_t(W)\xi\). In other words, at every time step, we take linear combinations of all past iterates of the simple gossip method.</p> <p>with \(\text{deg}P_t\leq t\) (to ensure that the \(x^t\) can be computed using at most \(t\) communication steps) and \(P_t(1)=1\) (to ensure that if all initial observations are equal, then \(x^t=\xi\) for any \(t\)).</p> <p>[matrices diagonalisées]</p>]]></content><author><name></name></author><category term="paper-study"/><category term="gossip"/><category term="math"/><category term="polytechnique"/><summary type="html"><![CDATA[Accelerated Gossip in Networks of Given Dimension using Jacobi Polynomial Iterations by Raphaël Berthier, Francis Bach and Pierre Gaillard]]></summary></entry><entry><title type="html">fairness with Wasserstein barycenters</title><link href="https://marcboelle.github.io/blog/2023/fairness/" rel="alternate" type="text/html" title="fairness with Wasserstein barycenters"/><published>2023-12-05T00:00:00+00:00</published><updated>2023-12-05T00:00:00+00:00</updated><id>https://marcboelle.github.io/blog/2023/fairness</id><content type="html" xml:base="https://marcboelle.github.io/blog/2023/fairness/"><![CDATA[<h2 id="the-challenge-of-algorithmic-fairness">The challenge of algorithmic fairness</h2> <p>When training a Machine Learning model, we make our predictor learn from the data which can be biased. For instance, if we want to decide how much an applicant would be paid, there will be a difference (in the reference data) between the wages of men and comen. But ideally, So the question is : how can we build a fair predictor when the training data is biased?</p> <h2 id="results-of-the-paper">Results of the paper</h2> <h3 id="problem-setting">Problem setting</h3> <p>The authors focus on regression problems \(Y=f^*(X,S)+\xi\), where \(f^*\) is the regression function minimizing the squared risk, \(S\) a sensitive attribute and \(\xi\) a (centered) noise.</p> <h3 id="demographic-parity-dp">Demographic Parity (DP)</h3> <p>To evaluate the fairness of some predictors, there are different metrics available. Demographic Parity is one of them and extensively used in the literature, in particular in this paper. Intuitively, it is satisfied if the distribution of the prediction is independent of the sensitive attribute.</p> <p>Formally, with \(S\) the attribute representing the sensitive groups in the population, a predictor \(g\) is fair (according to the DP criterion) if \(\forall (s,s')\in S^2,\:\:\sup_{t\in\mathbb{R}}\left|\mathbb{P}(g(X,S)\leq t|S=s)-\mathbb{P}(g(X,S)\leq t|S=s')\right|=0\) In other words, the Kolmogorov-Smirnov distance between the distributions on all sensitive groups must be \(0\).</p> <h3 id="strategy-of-the-authors">Strategy of the authors</h3> <p>From the optimal predictor \(f^*\), the authors suggests that we build a fair predictor \(g^*\) (w.r.t. DP) which remains “close” to \(f^*\) - to keep the accuracy as high as possible. We end up with this new problem : \(\min_{g\text{ is fair}}\mathbb{E}\left(f^*(X,S)-g(X,S)\right)^2\)</p> <p>Using Optimal Transport theory, the authors provide a closed form expression of \(g^*\) using Wasserstein barycenters</p> <h2 id="implementation">Implementation</h2>]]></content><author><name></name></author><category term="paper-study"/><category term="fairness"/><category term="math"/><category term="wasserstein"/><category term="polytechnique"/><summary type="html"><![CDATA[Fair Regression with Wasserstein Barycenters by Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Luca Oneto, and Massimiliano Pontil]]></summary></entry><entry><title type="html">weakly-supervised image classification challenge</title><link href="https://marcboelle.github.io/blog/2023/modal/" rel="alternate" type="text/html" title="weakly-supervised image classification challenge"/><published>2023-06-20T00:00:00+00:00</published><updated>2023-06-20T00:00:00+00:00</updated><id>https://marcboelle.github.io/blog/2023/modal</id><content type="html" xml:base="https://marcboelle.github.io/blog/2023/modal/"><![CDATA[<p>report available <a href="/assets/pdf/modal-report.pdf">here</a></p> <p>Framework (gossip problem): Given a network of agents represented as a graph, in which each agent holds a real value, we want to estimate the average of these values in a distributed manner. The agents (nodes) are related through links (edges), which they can use to communicate.</p> <p>The authors build a method for solving this problem that depends only on what they define as the <em>spectral dimension of the network</em>, which is intuitively the dimension of the space in which the agents live (for the grid in \(\mathbb{Z}^n\), the spectral dimension is \(n\)). Their method shows improvement over previous algorithms in the non-asymptotic regime, when the values are far from fully mixed.</p> <h2 id="the-gossip-problem-and-gossip-algorithms">The gossip problem and gossip algorithms</h2> <h3 id="the-gossip-problem">The gossip problem</h3> <p>The gossip problem, also known as the averaging problem, is fundamental in distributed frameworks, when information is shared among several machines without a central server. In this framework, we assume that each machine can communicate only with a few others, and these links are represented in a graph \(G=(V,E)\). Each machine hold an initial real value that the others do not know. The goal is then to find a way to get each machine to know the average of these initial values, through an iterative communication procedure and as quickly as possible.</p> <h4 id="problem-setting">Problem Setting</h4> <p>We are given an undirected finite graph \(G=(V,E)\), where \(V\) is the set of agents (nodes) in the network, and \(E\) the set of communication links (edges). Each node \(v\in V\) receives an initial real value \(\xi_v\) called an observation. We denote by \(\xi=(\xi_v)_{v\in V}\) the vector of observations, and the goal is then for each machine to know \(\bar\xi=\frac{1}{|V|}\sum_{v\in V}\xi_v\) through an iterative algorithm.</p> <p>\(x^t=(x^t_v)_{v\in V}\) denotes the values at time \(t\).</p> <p>NB : we are in in a synchronous framework, meaning that at every time step, all communciations are made at the same time (and not successively)</p> <h3 id="first-gossip-algorithms">First gossip algorithms</h3> <h4 id="simple-gossip">Simple gossip</h4> <p>Referred to as <em>simple gossip</em> in the paper, the landmark algorithm consists in the following intuitive scheme: at each iteration, each agent replaces his current value by an average of the values held by its neighbors. Formally, this means that we have a <strong>gossip matrix</strong> \(W\), which is stochastic, symmetric, nonnegative and supported by the graph : \(W_{u,v}&gt;0\implies \{u,v\}\in E\).</p> <p>Usual gossip matrices :</p> <ul> <li>in a \(d\)-regular graph (all vertices have degree \(d\)): \(W\)</li> <li>more generally, if all vertices have degree smaller than \(d_{\max}\): \(W\)</li> </ul> <p>Then the simple gossip algorithm consists in the updates \(x^{t+1}=Wx^t\). So \(x^t=W^t\xi\)</p> <h4 id="shift-register-gossip">Shift-register gossip</h4> <p>The idea of this second gossip algorithm is to take a linear combination of past iterates : \(x^{t+1}=\omega Wx^t+(1-\omega)x^{t-1}\) with \(x^0=\xi\) and \(x^1=W\xi\) Without going into the details of this algorithm, it is clear that the parameter \(\omega\) plays an important role and must be finetuned. It was shown in other papers (CITE?) that \(\omega=2\frac{1-\sqrt{\gamma(1-\gamma/4)}}{(1-\gamma/2)^2}\), which depends on the spectral gap gamma, works well, with an acceleration of convergence for small gammas (compared to simple gossip).</p> <p>This is a nice improvement since \(\gamma\) is indeed very small in large graphs. And in practicle cases, graph networks are quite big so it is a worthy improvement.</p> <p>Yet one important point here is that <strong>we assume that all agents know the spectral gap</strong> \(\gamma\). But in the general case, there is no reason why they should. Thus, the point of this paper is to find a way to avoid this difficulty by building a method based not on \(\gamma\) but on the spectral dimension of the graph.</p> <p><img src="../assets/img/gossip/grid-graph-Z2.png" alt="graph of spectral dimension $$2$$ in $$\mathbb{Z}^2$$"/></p> <h2 id="acceleration-with-jacobi-polynomials">Acceleration with Jacobi Polynomials</h2> <h3 id="polynomial-gossip">Polynomial gossip</h3> <p>Intuitively, polynomial gossip consists in replacing \(x^t=W^t\xi\) by \(x^t=P_t(W)\xi\). In other words, at every time step, we take linear combinations of all past iterates of the simple gossip method.</p> <p>with \(\text{deg}P_t\leq t\) (to ensure that the \(x^t\) can be computed using at most \(t\) communication steps) and \(P_t(1)=1\) (to ensure that if all initial observations are equal, then \(x^t=\xi\) for any \(t\)).</p> <p>[matrices diagonalisées]</p>]]></content><author><name></name></author><category term="challenge"/><category term="deep-learning"/><category term="computer-vision"/><category term="polytechnique"/><summary type="html"><![CDATA[Kaggle challenge from the course INF473V (Deep Learning in Computer Vision) at École Polytechnique]]></summary></entry></feed>